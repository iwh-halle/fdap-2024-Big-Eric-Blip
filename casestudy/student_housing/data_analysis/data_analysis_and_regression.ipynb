{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Casestudy Eric Bühler - Aachen </h1>\n",
    "\n",
    "In this notebook, some initial data analysis along with the regressions are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages used in this notebook\n",
    "import requests\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analysis of Verbindung and Verbindung möglich variables</h3>\n",
    "\n",
    "To avoid confusion with the fraternity variable, I have included two ways of evaluating wether a listing is a fraternity: Either by checking the provided texts for synonyms of fraternity or, since not all fraternities identify themselves as such, by looking for listings with low rent and a high number of roomates. To avoid colinearity however, only one of these should be included in the regression. To check wether we are not loosing a big amount of information, the following code checks the overlap of the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is at least one row where 'verbindung' is True and 'verbindung_moeglich' is False.\n",
      "There are 2 rows where 'verbindung' is True and 'verbindung_moeglich' is False.\n",
      "There is at least one row where 'verbindung' is False and 'verbindung_moeglich' is True.\n",
      "There are 19 rows where 'verbindung' is False and 'verbindung_moeglich' is True.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = '/workspaces/fdap-2024-Big-Eric-Blip/casestudy/student_housing/data_analysis/anzeigen.csv'  # Path to the CSV file\n",
    "anzeigen = pd.read_csv(file_path)\n",
    "\n",
    "# Condition checks\n",
    "condition_one = (anzeigen['verbindung'] == True) & (anzeigen['verbindung_moeglich'] == False)\n",
    "condition_two = (anzeigen['verbindung'] == False) & (anzeigen['verbindung_moeglich'] == True)\n",
    "\n",
    "# Check condition one\n",
    "rows_with_condition_one = anzeigen[condition_one]\n",
    "if not rows_with_condition_one.empty:\n",
    "    print(\"There is at least one row where 'verbindung' is True and 'verbindung_moeglich' is False.\")\n",
    "else:\n",
    "    print(\"There are no rows where 'verbindung' is True and 'verbindung_moeglich' is False.\")\n",
    "\n",
    "num_rows_one = condition_one.sum()\n",
    "print(f\"There are {num_rows_one} rows where 'verbindung' is True and 'verbindung_moeglich' is False.\")\n",
    "\n",
    "# Check condition two\n",
    "rows_with_condition_two = anzeigen[condition_two]\n",
    "if not rows_with_condition_two.empty:\n",
    "    print(\"There is at least one row where 'verbindung' is False and 'verbindung_moeglich' is True.\")\n",
    "else:\n",
    "    print(\"There are no rows where 'verbindung' is False and 'verbindung_moeglich' is True.\")\n",
    "\n",
    "num_rows_two = condition_two.sum()\n",
    "print(f\"There are {num_rows_two} rows where 'verbindung' is False and 'verbindung_moeglich' is True.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating NDVI of the districts</h3>\n",
    "\n",
    "In this cell, we extract the NDVI per PLZ from the [urban_green_spaces.ipynb](/workspaces/fdap-2024-Big-Eric-Blip/casestudy/student_housing/google_earth_engine/urban_green_spaces.ipynb) notebook and order them by descending NDVI. Districts with a high amount of vegetation will later be compared to districts with a high price point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted DataFrame by Decreasing mean NDVI:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plz_code</th>\n",
       "      <th>mean_ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52076</td>\n",
       "      <td>0.283134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52074</td>\n",
       "      <td>0.282947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52080</td>\n",
       "      <td>0.239880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52078</td>\n",
       "      <td>0.230341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52072</td>\n",
       "      <td>0.229945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52066</td>\n",
       "      <td>0.207245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52070</td>\n",
       "      <td>0.200926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52068</td>\n",
       "      <td>0.145891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52064</td>\n",
       "      <td>0.135038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52062</td>\n",
       "      <td>0.099158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plz_code  mean_ndvi\n",
       "6     52076   0.283134\n",
       "1     52074   0.282947\n",
       "9     52080   0.239880\n",
       "3     52078   0.230341\n",
       "4     52072   0.229945\n",
       "0     52066   0.207245\n",
       "2     52070   0.200926\n",
       "8     52068   0.145891\n",
       "7     52064   0.135038\n",
       "5     52062   0.099158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('/workspaces/fdap-2024-Big-Eric-Blip/casestudy/student_housing/google_earth_engine/ndvi_2020_results.csv')\n",
    "\n",
    "# Sort the DataFrame by 'mean_ndvi' in descending order\n",
    "sorted_df = df.sort_values(by='mean_ndvi', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(\"\\nSorted DataFrame by Decreasing mean NDVI:\")\n",
    "display(sorted_df)\n",
    "\n",
    "# Optionally, save the sorted DataFrame to a new CSV file\n",
    "sorted_df.to_csv('sorted_ndvi_2020_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Regressions</h2>\n",
    "\n",
    "<h3>Analysis of rent</h3>\n",
    "\n",
    "In the following code, we calculate a regression on the dependent variable 'price' by the independant variables bewohner, goresse, miete and plz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['const',\n",
       " 'bewohner',\n",
       " 'plz_52064',\n",
       " 'plz_52066',\n",
       " 'plz_52068',\n",
       " 'plz_52070',\n",
       " 'plz_52072',\n",
       " 'plz_52074',\n",
       " 'plz_52078',\n",
       " 'plz_52080',\n",
       " 'plz_52159',\n",
       " 'plz_52249']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.242\n",
      "Model:                            OLS   Adj. R-squared:                  0.206\n",
      "Method:                 Least Squares   F-statistic:                     6.700\n",
      "Date:                Tue, 09 Jul 2024   Prob (F-statistic):           9.98e-10\n",
      "Time:                        08:08:20   Log-Likelihood:                -830.21\n",
      "No. Observations:                 243   AIC:                             1684.\n",
      "Df Residuals:                     231   BIC:                             1726.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         32.1251      1.267     25.363      0.000      29.630      34.621\n",
      "x1            -1.3375      0.162     -8.232      0.000      -1.658      -1.017\n",
      "x2            -1.5010      1.533     -0.979      0.329      -4.522       1.520\n",
      "x3            -0.8414      1.897     -0.444      0.658      -4.579       2.896\n",
      "x4            -0.6627      2.756     -0.241      0.810      -6.092       4.767\n",
      "x5            -1.8734      1.597     -1.173      0.242      -5.021       1.274\n",
      "x6             1.1623      1.773      0.656      0.513      -2.331       4.655\n",
      "x7             0.9480      1.882      0.504      0.615      -2.760       4.656\n",
      "x8            -3.1899      3.274     -0.974      0.331      -9.640       3.260\n",
      "x9            -0.6254      5.466     -0.114      0.909     -11.395      10.144\n",
      "x10           -8.0202      7.645     -1.049      0.295     -23.083       7.043\n",
      "x11           -1.8803      4.500     -0.418      0.676     -10.747       6.987\n",
      "==============================================================================\n",
      "Omnibus:                       33.781   Durbin-Watson:                   1.782\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               44.853\n",
      "Skew:                           0.912   Prob(JB):                     1.82e-10\n",
      "Kurtosis:                       4.049   Cond. No.                         84.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "\n",
    "# Define the necessary columns for the DataFrame\n",
    "necessary_columns = ['bewohner', 'groesse', 'miete', 'plz']\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = '/workspaces/fdap-2024-Big-Eric-Blip/casestudy/student_housing/data_analysis/anzeigen.csv'  # Path to the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a DataFrame with only the necessary columns\n",
    "df = df[necessary_columns]\n",
    "\n",
    "# Convert numeric columns to numeric types and handle errors\n",
    "df['bewohner'] = pd.to_numeric(df['bewohner'], errors='coerce')\n",
    "df['groesse'] = pd.to_numeric(df['groesse'], errors='coerce')\n",
    "df['miete'] = pd.to_numeric(df['miete'], errors='coerce')\n",
    "\n",
    "# To ensure the rent is in rent per square meter:\n",
    "df['miete'] = df['miete'] / df['groesse']\n",
    "\n",
    "# Drop rows with missing values in numeric columns\n",
    "df = df.dropna(subset=['bewohner',  'miete'])\n",
    "\n",
    "# Convert 'plz' to categorical and create dummy variables\n",
    "df['plz'] = df['plz'].astype('category')\n",
    "df = pd.get_dummies(df, columns=['plz'], drop_first=True)\n",
    "\n",
    "# Add the intercept (constant term) for the regression model\n",
    "df = sm.add_constant(df)\n",
    "\n",
    "# Round numeric values to a specified number of decimal places\n",
    "df = df.round({'bewohner': 0, 'miete': 2})\n",
    "\n",
    "# Print data types and a sample of the DataFrame for debugging\n",
    "# Prepare the data for regression\n",
    "X = df.drop(columns=['miete','groesse'])  # Exclude dependent variable 'miete'\n",
    "y = df['miete']\n",
    "\n",
    "# Ensure all columns used for regression are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, forcing non-numeric to NaN\n",
    "X = X.fillna(0)  # Fill NaNs with 0 or some other value depending on context\n",
    "\n",
    "# Display only the column names\n",
    "display(X.columns.tolist())\n",
    "\n",
    "# Convert to np\n",
    "X = np.asarray(X)\n",
    "X = np.array(X , dtype=float)\n",
    "y = np.asarray(y)\n",
    "y = np.array(y, dtype=float)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression with custom variable names\n",
    "print(\"Regression Summary:\")\n",
    "print(model.summary())  # Coefficients table\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Analysis of listing-duration</h3>\n",
    "\n",
    "In the following code, we calculate a regression on the dependent variable 'online_seit' by the independant variables bewohner, goresse, miete, sentiment, verbindung and plz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['const',\n",
       " 'bewohner',\n",
       " 'groesse',\n",
       " 'miete',\n",
       " 'sentiment',\n",
       " 'plz_52064',\n",
       " 'plz_52066',\n",
       " 'plz_52068',\n",
       " 'plz_52070',\n",
       " 'plz_52072',\n",
       " 'plz_52074',\n",
       " 'plz_52078',\n",
       " 'plz_52080',\n",
       " 'plz_52159',\n",
       " 'plz_52249',\n",
       " 'verbindung_True']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.252\n",
      "Model:                            OLS   Adj. R-squared:                  0.202\n",
      "Method:                 Least Squares   F-statistic:                     5.087\n",
      "Date:                Tue, 09 Jul 2024   Prob (F-statistic):           1.18e-08\n",
      "Time:                        08:08:21   Log-Likelihood:                -506.25\n",
      "No. Observations:                 243   AIC:                             1045.\n",
      "Df Residuals:                     227   BIC:                             1100.\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.3152      1.253      3.444      0.001       1.846       6.784\n",
      "x1            -0.1268      0.055     -2.314      0.022      -0.235      -0.019\n",
      "x2             0.0055      0.036      0.154      0.878      -0.065       0.076\n",
      "x3             0.0098      0.023      0.421      0.674      -0.036       0.056\n",
      "x4            -0.0093      0.003     -2.707      0.007      -0.016      -0.003\n",
      "x5            -0.3601      0.411     -0.875      0.382      -1.171       0.451\n",
      "x6            -0.6605      0.508     -1.301      0.194      -1.661       0.340\n",
      "x7            -1.5045      0.741     -2.030      0.044      -2.965      -0.044\n",
      "x8            -1.0646      0.427     -2.494      0.013      -1.906      -0.223\n",
      "x9            -0.6847      0.473     -1.447      0.149      -1.617       0.247\n",
      "x10           -0.7431      0.517     -1.438      0.152      -1.762       0.275\n",
      "x11            0.6048      0.881      0.687      0.493      -1.130       2.340\n",
      "x12            0.0961      1.458      0.066      0.948      -2.777       2.969\n",
      "x13           -3.6010      2.049     -1.757      0.080      -7.639       0.437\n",
      "x14           -0.7162      1.208     -0.593      0.554      -3.096       1.664\n",
      "x15           -2.2848      0.574     -3.981      0.000      -3.416      -1.154\n",
      "==============================================================================\n",
      "Omnibus:                       13.454   Durbin-Watson:                   0.428\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.120\n",
      "Skew:                          -0.576   Prob(JB):                     0.000859\n",
      "Kurtosis:                       3.263   Cond. No.                     1.03e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.03e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "\n",
    "# Define the necessary columns for the DataFrame\n",
    "necessary_columns = ['bewohner', 'groesse', 'miete', 'plz','online_seit','sentiment','verbindung']\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = '/workspaces/fdap-2024-Big-Eric-Blip/casestudy/student_housing/data_analysis/anzeigen.csv'  # Path to the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a DataFrame with only the necessary columns\n",
    "df = df[necessary_columns]\n",
    "\n",
    "# Convert numeric columns to numeric types and handle errors\n",
    "df['bewohner'] = pd.to_numeric(df['bewohner'], errors='coerce')\n",
    "df['groesse'] = pd.to_numeric(df['groesse'], errors='coerce')\n",
    "df['miete'] = pd.to_numeric(df['miete'], errors='coerce')\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')*100\n",
    "df['online_seit'] = pd.to_numeric(df['online_seit'], errors='coerce')\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')\n",
    "df['verbindung'] = pd.to_numeric(df['verbindung'], errors='coerce')\n",
    "\n",
    "# To ensure the rent is in rent per square meter:\n",
    "df['miete'] = df['miete'] / df['groesse']\n",
    "\n",
    "# Drop rows with missing values in numeric columns\n",
    "df = df.dropna(subset=['bewohner', 'groesse', 'miete'])\n",
    "\n",
    "# Convert 'plz' to categorical and create dummy variables\n",
    "df['plz'] = df['plz'].astype('category')\n",
    "df['verbindung'] = df['verbindung'].astype('category')\n",
    "df = pd.get_dummies(df, columns=['plz'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['verbindung'], drop_first=True)\n",
    "\n",
    "# Add the intercept (constant term) for the regression model\n",
    "df = sm.add_constant(df)\n",
    "\n",
    "# Round numeric values to a specified number of decimal places\n",
    "df = df.round({'bewohner': 0, 'groesse': 0, 'miete': 2,'sentiment': 5})\n",
    "\n",
    "# Print data types and a sample of the DataFrame for debugging\n",
    "# Prepare the data for regression\n",
    "X = df.drop(columns=['online_seit'])  # Exclude dependent variable 'online_seit'\n",
    "y = np.log(df['online_seit'])\n",
    "\n",
    "# Ensure all columns used for regression are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, forcing non-numeric to NaN\n",
    "X = X.fillna(0)  # Fill NaNs with 0 or some other value depending on context\n",
    "\n",
    "# Display only the column names\n",
    "display(X.columns.tolist())\n",
    "\n",
    "# Convert to np\n",
    "X = np.asarray(X)\n",
    "X = np.array(X , dtype=float)\n",
    "y = np.asarray(y)\n",
    "y = np.array(y, dtype=float)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression with custom variable names\n",
    "print(\"Regression Summary:\")\n",
    "print(model.summary())  # Coefficients table\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
