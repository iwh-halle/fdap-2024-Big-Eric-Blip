{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Casestudy Eric Bühler - Aachen </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages used in this notebook\n",
    "import requests\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "from datetime import datetime, timedelta\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import openai\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCRAPER_API_KEY = '93d624551a355d2f8416326ea4c9e398'  # Replace with your Scraper API key\n",
    "\n",
    "def get_wg_links(pages=2):\n",
    "    links = []\n",
    "    for i in range(pages):\n",
    "        url = f\"https://www.wg-gesucht.de/wg-zimmer-in-Aachen.1.0.1.{i}.html?offer_filter=1&city_id=1&sort_order=0&noDeact=1&categories%5B%5D=0&pagination=1&pu=\"\n",
    "        scraper_api_url = f\"http://api.scraperapi.com?api_key={SCRAPER_API_KEY}&url={url}\"\n",
    "        response = requests.get(scraper_api_url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve {url}, status code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            continue\n",
    "\n",
    "        # Parse results\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extracting all Anzeigen\n",
    "        anzeigen_raw = soup.find_all('div', class_='col-sm-8 card_body')\n",
    "        for anzeige in anzeigen_raw:\n",
    "            anchor_tag = anzeige.find('a')\n",
    "            if anchor_tag and 'href' in anchor_tag.attrs:\n",
    "                links.append(\"https://www.wg-gesucht.de\" + anchor_tag['href'])\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_anzeigen_html(links):\n",
    "    anzeigen_html = []\n",
    "    for link in links:\n",
    "        scraper_api_url = f\"http://api.scraperapi.com?api_key={SCRAPER_API_KEY}&url={link}\"\n",
    "        response = requests.get(scraper_api_url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve {link}, status code: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            continue\n",
    "\n",
    "        # Convert the BeautifulSoup object to a string\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        anzeigen_html.append({'html': str(soup), 'link': link})\n",
    "\n",
    "    # Save the list of dictionaries to a JSON file\n",
    "    with open('html_pages.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(anzeigen_html, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return pd.DataFrame(anzeigen_html)\n",
    "\n",
    "def analyze_sentiment(article_text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(article_text)\n",
    "    return sentiment\n",
    "\n",
    "def calculate_composite_sentiment(zimmer_text,lage_text,wg_leben_text,sonstiges_text):\n",
    "    texts = {\n",
    "        'zimmer': zimmer_text,\n",
    "        'lage': lage_text,\n",
    "        'wg_leben': wg_leben_text,\n",
    "        'sonstiges': sonstiges_text\n",
    "    }\n",
    "\n",
    "    sentiments = {}\n",
    "    valid_compound_scores = []\n",
    "\n",
    "    for key, text in texts.items():\n",
    "        if text != 'Unknown':\n",
    "            sentiment = analyze_sentiment(text)\n",
    "            sentiments[key] = sentiment\n",
    "            valid_compound_scores.append(sentiment['compound'])\n",
    "        else:\n",
    "            sentiments[key] = {'compound': None, 'neg': None, 'neu': None, 'pos': None}\n",
    "\n",
    "    if valid_compound_scores:\n",
    "        overall_sentiment = sum(valid_compound_scores) / len(valid_compound_scores)\n",
    "    else:\n",
    "        overall_sentiment = None\n",
    "\n",
    "    sentiments['overall_sentiment'] = overall_sentiment\n",
    "\n",
    "    return sentiments\n",
    "\n",
    "FRATERNITIES=[\n",
    "    \"Studentenverbindung\", \n",
    "    \"Burschenschaft\", \n",
    "    \"Corps\", \n",
    "    \"Landsmannschaft\", \n",
    "    \"Akademische Verbindung\", \n",
    "    \"Studentische Verbindung\", \n",
    "    \"Studentenbund\",\n",
    "    \"Studentenverein\", \n",
    "    \"Studentenvereinigung\", \n",
    "    \"Kadergemeinschaft\",\n",
    "    \"Akademische Vereinigung\", \n",
    "    \"Studierendenverband\", \n",
    "    \"Akademische Gemeinschaft\",\n",
    "    \"Studentenbruderschaft\", \n",
    "    \"Universitätsgesellschaft\"\n",
    "]\n",
    "\n",
    "def contains_any_words(texts):\n",
    "    # Convert all texts to lower case for case-insensitive comparison\n",
    "    lower_texts = [text.lower() for text in texts]\n",
    "    \n",
    "    # Convert the words to lower case for case-insensitive comparison\n",
    "    lower_words = [word.lower() for word in FRATERNITIES]\n",
    "    \n",
    "    for text in lower_texts:\n",
    "        if any(word in text for word in lower_words):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def load_anzeigen_html(filename='html_pages.json'):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        anzeigen_html = json.load(file)\n",
    "\n",
    "    # Convert the HTML strings back to BeautifulSoup objects\n",
    "    for anzeige in anzeigen_html:\n",
    "        anzeige['html'] = BeautifulSoup(anzeige['html'], 'html.parser')\n",
    "\n",
    "    return pd.DataFrame(anzeigen_html)\n",
    "\n",
    "def get_anzeigen_from_html():\n",
    "    html_list = load_anzeigen_html()\n",
    "    anzeigen = []\n",
    "    errors = 0\n",
    "    for soup in html_list['html']:\n",
    "        try:\n",
    "            titel_element = soup.find('h1', class_='headline headline-detailed-view-title')\n",
    "            titel = titel_element.get_text().replace('\\n', '').strip() if titel_element else 'Unknown'\n",
    "\n",
    "            wg_groesse_element = soup.find('span', class_='mr5')\n",
    "            wg_groesse = wg_groesse_element['title'].split('er')[0].split()[0] if (wg_groesse_element and 'title' in wg_groesse_element.attrs) else 'Unknown'\n",
    "\n",
    "            key_facts = soup.find_all('b', class_='key_fact_value')\n",
    "            groesse = key_facts[0].get_text().split('m')[0].strip() if key_facts and len(key_facts) > 0 else 'Unknown'\n",
    "            miete = key_facts[1].get_text().split('€')[0].strip() if key_facts and len(key_facts) > 1 else 'Unknown'\n",
    "\n",
    "            minor_facts = soup.find_all('span', class_='section_panel_value')\n",
    "            kaltmiete = minor_facts[0].get_text().replace('€','').strip() if minor_facts and len(minor_facts) > 0 else 'Unknown'\n",
    "            nebenkosten = minor_facts[1].get_text().replace('€','').strip() if minor_facts and len(minor_facts) > 1 else 'Unknown'\n",
    "            sonstige_kosten = minor_facts[2].get_text().replace('€','').strip() if minor_facts and len(minor_facts) > 2 else 'Unknown'\n",
    "            kaution = minor_facts[3].get_text().replace('€','').strip() if minor_facts and len(minor_facts) > 3 else 'Unknown'\n",
    "            abloesevereinb = minor_facts[4].get_text().replace('€','').strip() if minor_facts and len(minor_facts) > 4 else 'Unknown'\n",
    "            frei_ab = minor_facts[5].get_text().strip() if minor_facts and len(minor_facts) > 5 else 'Unknown'\n",
    "\n",
    "            adresse = soup.find_all('a', href='#mapContainer')\n",
    "            strasse = adresse[0].get_text().strip().split()[0] if adresse else 'Unknown'\n",
    "            plz = next((text for text in adresse[0].get_text().strip().split() if re.fullmatch(r'\\d{5}', text)), 'Unknown') if adresse else 'Unknown'\n",
    "\n",
    "            online_seit = 'Unknown'\n",
    "            green_style = soup.find('b', style='color: #218700;')\n",
    "            grey_style = soup.find('b', style='color: #898989;')\n",
    "\n",
    "            if green_style:\n",
    "                online_seit = green_style.get_text().strip()\n",
    "            elif grey_style:\n",
    "                online_seit = grey_style.get_text().strip()\n",
    "\n",
    "            if \"Sekunde\" in online_seit or \"Sekunden\" in online_seit:\n",
    "                online_seit = 0,0\n",
    "            elif \"Minuten\" in online_seit or \"Minute\" in online_seit:\n",
    "                minutes = ''.join(filter(str.isdigit, online_seit))\n",
    "                #online_seit = f\"00:{minutes.zfill(2)}\"\n",
    "                online_seit = 0.01 * int(minutes)\n",
    "            elif \"Stunden\" in online_seit or \"Stunde\" in online_seit:\n",
    "                hours = ''.join(filter(str.isdigit, online_seit))\n",
    "                #online_seit = f\"{hours.zfill(2)}:00\"\n",
    "                online_seit = int(hours)\n",
    "            elif \"Tag\" in online_seit or \"Tage\" in online_seit:\n",
    "                days = ''.join(filter(str.isdigit, online_seit))\n",
    "                online_seit = int(days) * 24\n",
    "                #online_seit = f\"{hours}:00\"\n",
    "            else:\n",
    "                try:\n",
    "                    date_format = \"%d.%m.%Y\"\n",
    "                    online_date = datetime.strptime(online_seit, date_format)\n",
    "                    current_date = datetime.now()\n",
    "                    days_ago = (current_date - online_date).days\n",
    "                    online_seit = int(days_ago)*24\n",
    "                except ValueError:\n",
    "                    # Handle the case where the date is not in the expected format\n",
    "                    online_seit = \"Unknown\"\n",
    "\n",
    "\n",
    "            zimmer = soup.find('div', id='freitext_0')\n",
    "            zimmer = zimmer.find('p').get_text().strip() \n",
    "            zimmer = re.sub('[^a-zA-ZäöüÄÖÜß-]', ' ', zimmer) if zimmer else 'Unknown'\n",
    "\n",
    "            lage = soup.find('div', id='freitext_1')\n",
    "            lage = lage.find('p').get_text().strip() \n",
    "            lage = re.sub('[^a-zA-ZäöüÄÖÜß-]', ' ', lage) if lage else 'Unknown'\n",
    "\n",
    "            wg_leben = soup.find('div', id='freitext_2')\n",
    "            wg_leben = wg_leben.find('p').get_text().strip() \n",
    "            wg_leben = re.sub('[^a-zA-ZäöüÄÖÜß-]', ' ', wg_leben) if wg_leben else 'Unknown'\n",
    "\n",
    "            sonstiges = soup.find('div', id='freitext_3')\n",
    "            sonstiges = sonstiges.find('p').get_text().strip()\n",
    "            sonstiges = re.sub('[^a-zA-ZäöüÄÖÜß-]', ' ', sonstiges) if sonstiges else 'Unknown'\n",
    "\n",
    "            fraternity = contains_any_words([zimmer,lage,wg_leben,sonstiges])\n",
    "            fraternity_likely = (int(wg_groesse)>5) & (int(miete)<500)\n",
    "         \n",
    "            sentiment=calculate_composite_sentiment(zimmer,lage,wg_leben,sonstiges)['overall_sentiment']\n",
    "\n",
    "            link = html_list['link'].iloc[0]\n",
    "\n",
    "            anzeigen.append({\n",
    "                'titel': titel,\n",
    "                'bewohner': int(wg_groesse),\n",
    "                'groesse': int(groesse),\n",
    "                'miete': int(miete),\n",
    "                'strasse': strasse,\n",
    "                'plz': int(plz),\n",
    "                'online_seit': online_seit,\n",
    "                'sentiment': float(sentiment),\n",
    "                'verbindung': fraternity,\n",
    "                'verbindung_moeglich': fraternity_likely,\n",
    "                'zimmer': zimmer,\n",
    "                'lage': lage,\n",
    "                'wg_leben': wg_leben,\n",
    "                'sonstiges': sonstiges,\n",
    "                'link': link\n",
    "                \n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            #print(f\"An error occurred: {e}, link: {html_list['link'].iloc[0]}\")\n",
    "            errors += 1\n",
    "            continue\n",
    "            # Specify the file path\n",
    "    file_path = 'anzeigen.csv'\n",
    "    # Save DataFrame to CSV\n",
    "    pd.DataFrame(anzeigen).to_csv(file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    return pd.DataFrame(anzeigen)\n",
    "\n",
    "#Get new links, State how many pages (20 links per page) => Call with 20 -> 400 listings\n",
    "#links = get_wg_links(20)\n",
    "\n",
    "#Get the html\n",
    "#anzeigen_html = get_anzeigen_html(links)\n",
    "\n",
    "#Get Dataframe\n",
    "anzeigen = get_anzeigen_from_html()\n",
    "display(anzeigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is at least one row where 'verbindung' is True and 'verbindung_moeglich' is False.\n",
      "There are 2 rows where 'verbindung' is True and 'verbindung_moeglich' is False.\n",
      "There is at least one row where 'verbindung' is False and 'verbindung_moeglich' is True.\n",
      "There are 19 rows where 'verbindung' is False and 'verbindung_moeglich' is True.\n"
     ]
    }
   ],
   "source": [
    "# Condition checks\n",
    "condition_one = (anzeigen['verbindung'] == True) & (anzeigen['verbindung_moeglich'] == False)\n",
    "condition_two = (anzeigen['verbindung'] == False) & (anzeigen['verbindung_moeglich'] == True)\n",
    "\n",
    "# Check condition one\n",
    "rows_with_condition_one = anzeigen[condition_one]\n",
    "if not rows_with_condition_one.empty:\n",
    "    print(\"There is at least one row where 'verbindung' is True and 'verbindung_moeglich' is False.\")\n",
    "else:\n",
    "    print(\"There are no rows where 'verbindung' is True and 'verbindung_moeglich' is False.\")\n",
    "\n",
    "num_rows_one = condition_one.sum()\n",
    "print(f\"There are {num_rows_one} rows where 'verbindung' is True and 'verbindung_moeglich' is False.\")\n",
    "\n",
    "# Check condition two\n",
    "rows_with_condition_two = anzeigen[condition_two]\n",
    "if not rows_with_condition_two.empty:\n",
    "    print(\"There is at least one row where 'verbindung' is False and 'verbindung_moeglich' is True.\")\n",
    "else:\n",
    "    print(\"There are no rows where 'verbindung' is False and 'verbindung_moeglich' is True.\")\n",
    "\n",
    "num_rows_two = condition_two.sum()\n",
    "print(f\"There are {num_rows_two} rows where 'verbindung' is False and 'verbindung_moeglich' is True.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted DataFrame by Decreasing mean NDVI:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plz_code</th>\n",
       "      <th>mean_ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52076</td>\n",
       "      <td>0.283134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52074</td>\n",
       "      <td>0.282947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52080</td>\n",
       "      <td>0.239880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52078</td>\n",
       "      <td>0.230341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52072</td>\n",
       "      <td>0.229945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52066</td>\n",
       "      <td>0.207245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52070</td>\n",
       "      <td>0.200926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52068</td>\n",
       "      <td>0.145891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52064</td>\n",
       "      <td>0.135038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52062</td>\n",
       "      <td>0.099158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   plz_code  mean_ndvi\n",
       "6     52076   0.283134\n",
       "1     52074   0.282947\n",
       "9     52080   0.239880\n",
       "3     52078   0.230341\n",
       "4     52072   0.229945\n",
       "0     52066   0.207245\n",
       "2     52070   0.200926\n",
       "8     52068   0.145891\n",
       "7     52064   0.135038\n",
       "5     52062   0.099158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv('/workspaces/fdap-2024-Big-Eric-Blip/casestudy/student_housing/google_earth_engine/ndvi_2020_results.csv')\n",
    "\n",
    "# Sort the DataFrame by 'mean_ndvi' in descending order\n",
    "sorted_df = df.sort_values(by='mean_ndvi', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(\"\\nSorted DataFrame by Decreasing mean NDVI:\")\n",
    "display(sorted_df)\n",
    "\n",
    "# Optionally, save the sorted DataFrame to a new CSV file\n",
    "sorted_df.to_csv('sorted_ndvi_2020_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>bewohner</th>\n",
       "      <th>groesse</th>\n",
       "      <th>plz_52064</th>\n",
       "      <th>plz_52066</th>\n",
       "      <th>plz_52068</th>\n",
       "      <th>plz_52070</th>\n",
       "      <th>plz_52072</th>\n",
       "      <th>plz_52074</th>\n",
       "      <th>plz_52078</th>\n",
       "      <th>plz_52080</th>\n",
       "      <th>plz_52159</th>\n",
       "      <th>plz_52249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  bewohner  groesse  plz_52064  plz_52066  plz_52068  plz_52070  \\\n",
       "0    1.0        11       20      False      False      False      False   \n",
       "\n",
       "   plz_52072  plz_52074  plz_52078  plz_52080  plz_52159  plz_52249  \n",
       "0      False       True      False      False      False      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.424\n",
      "Model:                            OLS   Adj. R-squared:                  0.394\n",
      "Method:                 Least Squares   F-statistic:                     14.09\n",
      "Date:                Thu, 04 Jul 2024   Prob (F-statistic):           8.40e-22\n",
      "Time:                        12:08:40   Log-Likelihood:                -1426.6\n",
      "No. Observations:                 243   AIC:                             2879.\n",
      "Df Residuals:                     230   BIC:                             2925.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        386.5121     25.860     14.946      0.000     335.560     437.464\n",
      "x1           -20.6755      1.895    -10.908      0.000     -24.410     -16.941\n",
      "x2             6.7435      1.252      5.388      0.000       4.278       9.209\n",
      "x3           -13.5769     17.897     -0.759      0.449     -48.840      21.686\n",
      "x4             1.6808     22.130      0.076      0.940     -41.923      45.284\n",
      "x5           -22.5797     32.260     -0.700      0.485     -86.143      40.984\n",
      "x6           -12.5179     18.644     -0.671      0.503     -49.252      24.216\n",
      "x7            26.1587     20.689      1.264      0.207     -14.605      66.922\n",
      "x8            -5.2490     22.126     -0.237      0.813     -48.844      38.346\n",
      "x9           -58.1139     38.221     -1.520      0.130    -133.422      17.195\n",
      "x10           38.6576     63.776      0.606      0.545     -87.002     164.317\n",
      "x11         -139.5704     89.246     -1.564      0.119    -315.415      36.275\n",
      "x12            8.7750     52.525      0.167      0.867     -94.716     112.266\n",
      "==============================================================================\n",
      "Omnibus:                       38.425   Durbin-Watson:                   1.759\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               67.169\n",
      "Skew:                           0.854   Prob(JB):                     2.60e-15\n",
      "Kurtosis:                       4.928   Cond. No.                         278.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "\n",
    "# Define the necessary columns for the DataFrame\n",
    "necessary_columns = ['bewohner', 'groesse', 'miete', 'plz']\n",
    "\n",
    "# Create a DataFrame from the 'anzeigen' list with only the necessary columns\n",
    "df = pd.DataFrame(anzeigen, columns=necessary_columns)\n",
    "\n",
    "# Convert numeric columns to numeric types and handle errors\n",
    "df['bewohner'] = pd.to_numeric(df['bewohner'], errors='coerce')\n",
    "df['groesse'] = pd.to_numeric(df['groesse'], errors='coerce')\n",
    "df['miete'] = pd.to_numeric(df['miete'], errors='coerce')\n",
    "#df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values in numeric columns\n",
    "df = df.dropna(subset=['bewohner', 'groesse', 'miete'])\n",
    "\n",
    "# Convert 'plz' to categorical and create dummy variables\n",
    "df['plz'] = df['plz'].astype('category')\n",
    "df = pd.get_dummies(df, columns=['plz'], drop_first=True)\n",
    "\n",
    "# Add the intercept (constant term) for the regression model\n",
    "df = sm.add_constant(df)\n",
    "\n",
    "# Round numeric values to a specified number of decimal places\n",
    "df = df.round({'bewohner': 0, 'groesse': 0, 'miete': 2})\n",
    "\n",
    "# Print data types and a sample of the DataFrame for debugging\n",
    "# Prepare the data for regression\n",
    "X = df.drop(columns=['miete'])  # Exclude dependent variable 'miete'\n",
    "y = df['miete']\n",
    "\n",
    "# Ensure all columns used for regression are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, forcing non-numeric to NaN\n",
    "X = X.fillna(0)  # Fill NaNs with 0 or some other value depending on context\n",
    "\n",
    "# Get variable names (column names)\n",
    "variable_names = X.columns if hasattr(X, 'columns') else list(df.columns.difference(['miete']))\n",
    "display(X[0:1])\n",
    "\n",
    "# Convert to np\n",
    "X = np.asarray(X)\n",
    "X = np.array(X , dtype=float)\n",
    "y = np.asarray(y)\n",
    "y = np.array(y, dtype=float)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "\n",
    "\n",
    "# Print the summary of the regression with custom variable names\n",
    "print(\"Regression Summary:\")\n",
    "print(model.summary())  # Coefficients table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>bewohner</th>\n",
       "      <th>groesse</th>\n",
       "      <th>miete</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>plz_52064</th>\n",
       "      <th>plz_52066</th>\n",
       "      <th>plz_52068</th>\n",
       "      <th>plz_52070</th>\n",
       "      <th>plz_52072</th>\n",
       "      <th>plz_52074</th>\n",
       "      <th>plz_52078</th>\n",
       "      <th>plz_52080</th>\n",
       "      <th>plz_52159</th>\n",
       "      <th>plz_52249</th>\n",
       "      <th>verbindung_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>265</td>\n",
       "      <td>-40.675</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  bewohner  groesse  miete  sentiment  plz_52064  plz_52066  \\\n",
       "0    1.0        11       20    265    -40.675      False      False   \n",
       "\n",
       "   plz_52068  plz_52070  plz_52072  plz_52074  plz_52078  plz_52080  \\\n",
       "0      False      False      False       True      False      False   \n",
       "\n",
       "   plz_52159  plz_52249  verbindung_True  \n",
       "0      False      False             True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.258\n",
      "Model:                            OLS   Adj. R-squared:                  0.209\n",
      "Method:                 Least Squares   F-statistic:                     5.251\n",
      "Date:                Thu, 04 Jul 2024   Prob (F-statistic):           5.51e-09\n",
      "Time:                        12:08:49   Log-Likelihood:                -492.74\n",
      "No. Observations:                 243   AIC:                             1017.\n",
      "Df Residuals:                     227   BIC:                             1073.\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.3746      0.805      5.438      0.000       2.789       5.960\n",
      "x1            -0.1229      0.052     -2.348      0.020      -0.226      -0.020\n",
      "x2            -0.0042      0.029     -0.143      0.887      -0.062       0.054\n",
      "x3             0.0004      0.002      0.283      0.777      -0.003       0.003\n",
      "x4            -0.0086      0.003     -2.658      0.008      -0.015      -0.002\n",
      "x5            -0.3255      0.387     -0.840      0.402      -1.089       0.438\n",
      "x6            -0.5943      0.480     -1.238      0.217      -1.540       0.352\n",
      "x7            -1.3841      0.700     -1.978      0.049      -2.763      -0.005\n",
      "x8            -0.9897      0.403     -2.453      0.015      -1.785      -0.195\n",
      "x9            -0.6375      0.450     -1.418      0.158      -1.524       0.249\n",
      "x10           -0.6417      0.490     -1.309      0.192      -1.607       0.324\n",
      "x11            0.5891      0.832      0.708      0.480      -1.050       2.228\n",
      "x12            0.2496      1.379      0.181      0.857      -2.468       2.967\n",
      "x13           -3.4284      1.936     -1.771      0.078      -7.243       0.387\n",
      "x14           -0.5009      1.143     -0.438      0.662      -2.752       1.751\n",
      "x15           -2.2584      0.550     -4.107      0.000      -3.342      -1.175\n",
      "==============================================================================\n",
      "Omnibus:                       18.982   Durbin-Watson:                   0.440\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.154\n",
      "Skew:                          -0.666   Prob(JB):                     2.55e-05\n",
      "Kurtosis:                       3.560   Cond. No.                     6.77e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.77e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "\n",
    "# Define the necessary columns for the DataFrame\n",
    "necessary_columns = ['bewohner', 'groesse', 'miete', 'plz','online_seit','sentiment','verbindung']\n",
    "\n",
    "# Create a DataFrame from the 'anzeigen' list with only the necessary columns\n",
    "df = pd.DataFrame(anzeigen, columns=necessary_columns)\n",
    "\n",
    "# Convert numeric columns to numeric types and handle errors\n",
    "df['bewohner'] = pd.to_numeric(df['bewohner'], errors='coerce')\n",
    "df['groesse'] = pd.to_numeric(df['groesse'], errors='coerce')\n",
    "df['miete'] = pd.to_numeric(df['miete'], errors='coerce')\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')*100\n",
    "df['online_seit'] = pd.to_numeric(df['online_seit'], errors='coerce')\n",
    "df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')\n",
    "df['verbindung'] = pd.to_numeric(df['verbindung'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values in numeric columns\n",
    "df = df.dropna(subset=['bewohner', 'groesse', 'miete'])\n",
    "\n",
    "# Convert 'plz' to categorical and create dummy variables\n",
    "df['plz'] = df['plz'].astype('category')\n",
    "df['verbindung'] = df['verbindung'].astype('category')\n",
    "df = pd.get_dummies(df, columns=['plz'], drop_first=True)\n",
    "df = pd.get_dummies(df, columns=['verbindung'], drop_first=True)\n",
    "\n",
    "# Add the intercept (constant term) for the regression model\n",
    "df = sm.add_constant(df)\n",
    "\n",
    "# Round numeric values to a specified number of decimal places\n",
    "df = df.round({'bewohner': 0, 'groesse': 0, 'miete': 2,'sentiment': 5})\n",
    "\n",
    "# Print data types and a sample of the DataFrame for debugging\n",
    "# Prepare the data for regression\n",
    "X = df.drop(columns=['online_seit'])  # Exclude dependent variable 'online_seit'\n",
    "y = np.log(df['online_seit'])\n",
    "\n",
    "# Ensure all columns used for regression are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, forcing non-numeric to NaN\n",
    "X = X.fillna(0)  # Fill NaNs with 0 or some other value depending on context\n",
    "\n",
    "# Get variable names (column names)\n",
    "display(X[0:1])\n",
    "\n",
    "# Convert to np\n",
    "X = np.asarray(X)\n",
    "X = np.array(X , dtype=float)\n",
    "y = np.asarray(y)\n",
    "y = np.array(y, dtype=float)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "\n",
    "\n",
    "# Print the summary of the regression with custom variable names\n",
    "print(\"Regression Summary:\")\n",
    "print(model.summary())  # Coefficients table\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
